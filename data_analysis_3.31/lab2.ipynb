{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previous on Weekly-Lab\n",
    "上次动手实验室，\n",
    "我们完成了一个爬虫，\n",
    "获取了校园卡的消费记录。\n",
    "\n",
    "无论上次你参没参加，\n",
    "无论你完成得好与不好，\n",
    "为了统一进度，\n",
    "还请同步git仓库。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 依赖\n",
    "\n",
    "- requests\n",
    "- pandas\n",
    "- BeautifulSoup\n",
    "- matplotlib\n",
    "- Pillow\n",
    "\n",
    "安装\n",
    "- windows  `py -3 -m pip install beautifulsoup4 matplotlib pandas Pillow requests` \n",
    "- unix     `python3 -m pip install beautifulsoup4 matplotlib pandas Pillow requests` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取消费记录\n",
    "\n",
    "如果你已经同步了仓库，那么你的目录下便会有一个`tutorial_ecard_2.py`文件。运行下面的代码块`%run tutorial_ecard_2.py`，能获取到校园卡的消费信息。\n",
    "\n",
    "没出意外的话，你的目录下应该已经有了`data.csv`。你可以用文本编辑器打开它，里面正是你的消费记录。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入验证码:8524\n",
      "请输入用户名:20155047\n",
      "请输入密码:········\n",
      "日期样式：2018-03-11\n",
      "日期样式：2018-03-11\n",
      "请输入查询起始日期:2018-03-01\n",
      "请输入查询终止日期:2018-03-20\n",
      "[<a disabled=\"true\">&lt;&lt;</a>, <a disabled=\"true\">&lt;</a>, <a class=\"aspnetpager\" href=\"javascript:__doPostBack('ctl00$ContentPlaceHolder1$AspNetPager1','2')\">2</a>, <a class=\"aspnetpager\" href=\"javascript:__doPostBack('ctl00$ContentPlaceHolder1$AspNetPager1','3')\">3</a>, <a class=\"aspnetpager\" href=\"javascript:__doPostBack('ctl00$ContentPlaceHolder1$AspNetPager1','4')\">4</a>, <a class=\"aspnetpager\" href=\"javascript:__doPostBack('ctl00$ContentPlaceHolder1$AspNetPager1','5')\">5</a>, <a class=\"aspnetpager\" href=\"javascript:__doPostBack('ctl00$ContentPlaceHolder1$AspNetPager1','6')\">6</a>, <a class=\"aspnetpager\" href=\"javascript:__doPostBack('ctl00$ContentPlaceHolder1$AspNetPager1','7')\">7</a>, <a class=\"aspnetpager\" href=\"javascript:__doPostBack('ctl00$ContentPlaceHolder1$AspNetPager1','8')\">8</a>, <a class=\"aspnetpager\" href=\"javascript:__doPostBack('ctl00$ContentPlaceHolder1$AspNetPager1','2')\">&gt;</a>, <a class=\"aspnetpager\" href=\"javascript:__doPostBack('ctl00$ContentPlaceHolder1$AspNetPager1','8')\">&gt;&gt;</a>]\n",
      "File saved: data.csv\n"
     ]
    }
   ],
   "source": [
    "%run tutorial_ecard_2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pandas\n",
    "> 最大的心愿是去掉黑眼圈和拍一张彩色照片。\n",
    "\n",
    "pandas 是一种列存数据分析 API，它是用于处理和分析输入数据的强大工具。\n",
    "\n",
    "先导入pandas库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.18.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pandas 主要有两种数据结构：\n",
    "  - Series，它是一列数据。大概类似于 Python 中的列表。\n",
    "  - DataFrame，类似于表格。DataFrame 中包含一个或多个 Series。Series 便是表格中的列，每个 Series 都有一个列名。\n",
    "  \n",
    "\n",
    "| A  | B  |  C | D  |  E  | F\n",
    "---|---|---|---|---|---|---\n",
    "0  | 1.0 |2013-01-02 | 1.0 | 3 |  test | foo\n",
    "1  | 1.0 |2013-01-02 | 1.0 | 3 | train | foo\n",
    "2  | 1.0 |2013-01-02 | 1.0 | 3 |  test | foo\n",
    "3  | 1.0 |2013-01-02 | 1.0 | 3 | train | foo\n",
    "\n",
    "上表中的\n",
    "- A {1.0,1.0,1.0,1.0}\n",
    "- B {2013-01-02,2013-01-02,2013-01-02,2013-01-02}\n",
    "- ...\n",
    "- E {test,train,test,train}\n",
    "- ...\n",
    "\n",
    "便相当于 Sereis，整个表格便相当于DataFrame。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以用 `pandas.DataFrame` 和 `pandas.Series` 构造这两个结构。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    San Francisco\n",
       "1         San Jose\n",
       "2       Sacramento\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(['San Francisco', 'San Jose', 'Sacramento']) # 用列表生成 Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2018-04-01', '2018-04-02', '2018-04-03', '2018-04-04',\n",
       "               '2018-04-05', '2018-04-06'],\n",
       "              dtype='datetime64[ns]', freq='D')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.date_range('20180401', periods=6) # pandas 也有一些生成 Series 的方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City name</th>\n",
       "      <th>Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>San Francisco</td>\n",
       "      <td>852469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>San Jose</td>\n",
       "      <td>1015785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sacramento</td>\n",
       "      <td>485199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       City name  Population\n",
       "0  San Francisco      852469\n",
       "1       San Jose     1015785\n",
       "2     Sacramento      485199"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_names = pd.Series(['San Francisco', 'San Jose', 'Sacramento'])\n",
    "population = pd.Series([852469, 1015785, 485199])\n",
    "\n",
    "# 而 DataFrame 可以用 列名:Series 这样的字典创建。\n",
    "cities = pd.DataFrame({ 'City name': city_names, 'Population': population }) \n",
    "\n",
    "cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "既然 DataFrame 可以用字典来构造，一般来说 DataFrame 也会表现得比较像字典。在很多对象中都有这样的规律。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    San Francisco\n",
       "1         San Jose\n",
       "2       Sacramento\n",
       "Name: City name, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities['City name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     852469\n",
       "1    1015785\n",
       "2     485199\n",
       "Name: Population, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities['Population']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City name</th>\n",
       "      <th>Population</th>\n",
       "      <th>Area square miles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>San Francisco</td>\n",
       "      <td>852469</td>\n",
       "      <td>46.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>San Jose</td>\n",
       "      <td>1015785</td>\n",
       "      <td>176.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sacramento</td>\n",
       "      <td>485199</td>\n",
       "      <td>97.92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       City name  Population  Area square miles\n",
       "0  San Francisco      852469              46.87\n",
       "1       San Jose     1015785             176.53\n",
       "2     Sacramento      485199              97.92"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities['Area square miles'] = pd.Series([46.87, 176.53, 97.92]) # 可以直接往里面添加/修改列\n",
    "\n",
    "cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同样，Series 也表现得很像列表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'San Francisco'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities['City name'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    San Francisco\n",
       "1         San Jose\n",
       "Name: City name, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities['City name'][0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 操纵数据\n",
    "用pandas可以很简便地操纵数据。例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     852.469\n",
       "1    1015.785\n",
       "2     485.199\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population / 1000.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "并且，你可以用 .apply 函数，实现 map 的功能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1     True\n",
       "2    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population.apply(lambda val: val > 1000000) # 生成新列，布尔值表示 population 是否大于 1,000,000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "甚至，你可以直接做列与列的计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City name</th>\n",
       "      <th>Population</th>\n",
       "      <th>Area square miles</th>\n",
       "      <th>Population density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>San Francisco</td>\n",
       "      <td>852469</td>\n",
       "      <td>46.87</td>\n",
       "      <td>18187.945381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>San Jose</td>\n",
       "      <td>1015785</td>\n",
       "      <td>176.53</td>\n",
       "      <td>5754.177760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sacramento</td>\n",
       "      <td>485199</td>\n",
       "      <td>97.92</td>\n",
       "      <td>4955.055147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       City name  Population  Area square miles  Population density\n",
       "0  San Francisco      852469              46.87        18187.945381\n",
       "1       San Jose     1015785             176.53         5754.177760\n",
       "2     Sacramento      485199              97.92         4955.055147"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities['Population density'] = cities['Population'] / cities['Area square miles'] # 人口密度 = 人口 / 面积\n",
    "cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "练习：已知San Francisco, San Jose, Sacramento 的 GDP 分别为：43170.4, 23522.2, 11882.2 （单位：百万美元）。为 DataFrame 添加 GDP 列，并计算人均 GDP (单位：美元）。（参考数据不一定真实）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cities['GDP'] = \n",
    "cities['GDP per capita'] =\n",
    "cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考答案\n",
    "<p style=\"color:#000;background-color:#000;\">\n",
    "cities['GDP'] = pd.Series([43170.4, 23522.2, 11882.2])<br/>\n",
    "cities['GDP per capita'] = cities['GDP'] * 1000000 / cities['Population']\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "另外，对 Series 和 DataFrames 还有一些统计相关的方法。你可以从[这里](http://pandas.pydata.org/pandas-docs/stable/basics.html#descriptive-statistics)查看更多的文档。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cities['Population'].sum() # 计算总人口"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cities['Population'].mean() # 计算平均人口"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cities['Population'].max() # 计算最大值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 消费数据的处理\n",
    "\n",
    "pandas 提供了一些API供我们读取数据，常见的，用 `pandas.read_csv` 读取csv文件（这个函数不仅可以读取本地的，也可以读取网络的）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xb9 in position 0: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-9e6dd39185a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconsume_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mconsume_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    560\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    561\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    643\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    797\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    800\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1211\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas\\parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas\\parser.c:5129)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._get_header (pandas\\parser.c:7634)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xb9 in position 0: invalid start byte"
     ]
    }
   ],
   "source": [
    "consume_data = pd.read_csv('data.csv') \n",
    "consume_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "操作时间 这一列的数据的类型是字符串，我们先转化一下格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "consume_data['操作时间'] = pd.to_datetime(consume_data['操作时间']) # 格式化“操作时间”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以用 `groupby` 函数，对data进行分类。`groupby`第一个参数（也是通常使用的参数）是分类的依据，一般是列名。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped = consume_data.groupby('科目描述') # 按照科目描述这列分类\n",
    "\n",
    "grouped.get_group('餐费支出') # 例如这样就获得了所有餐费支出的数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "也可以对 grouped 进行诸如求和这样的操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "但是，钱包余额也被求和了，这是我们不想要的。我们可以仅选中其中的几列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped[['钱包交易金额']].sum()\n",
    "# 为什么这里索引用的是 [[ ]] 呢？去掉里面的方括号试一下，想一下为什么。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提示:<span style=\"color:#000;background-color:#000;\">\n",
    "[] 得到的是一个 Series, [[ ]] 得到的是一个 DataFrame。\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`groupby`也支持用`Grouper`对象进行分类，例如下面这段代码就按每天分类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped2 = consume_data.groupby(pd.Grouper(freq='1D',key='操作时间')) \n",
    "grouped2[['钱包交易金额']].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "练习：获得在每个终端消费的总金额。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped3 = ______\n",
    "grouped3______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考答案：\n",
    "<p style=\"color:#000;background-color:#000;\">\n",
    "grouped3 = consume_data.groupby('终端名称') <br/>\n",
    "grouped3[['钱包交易金额']].sum()\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 绘制图表\n",
    "\n",
    "在绘制图标之前，我们需要先设置一下字体，否则中文字符会无法显示。\n",
    "\n",
    "如果设置了之后，中文仍不能正常显示，可以：\n",
    "1. 安装 pypinyin\n",
    "   - windows  `py -3 -m pip install pypinyin` \n",
    "   - unix     `python3 -m pip install pypinyin` \n",
    "2. 运行目录下的`topinyin.py`将所有中文字符转换成拼音"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "# 上面一句用于jupyter，非jupyter请删掉。\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rc('font', family=['KaiTi']) # 在这个列表里加入字体名\n",
    "matplotlib.pyplot.rcParams['axes.unicode_minus']=False # 用来正常显示负号"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以绘制钱包余额关于操作时间的折线图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "consume_data.plot(x='操作时间',y='钱包余额')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "也可以指定kind参数绘制饼状图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped.sum().plot(x='终端名称',y='钱包交易金额',kind='pie')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "也可以绘制条形图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped2[['钱包交易金额']].sum().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "具体 kind 有这些选项： \n",
    "- ‘line’ : line plot (default)\n",
    "- ‘bar’ : vertical bar plot\n",
    "- ‘barh’ : horizontal bar plot\n",
    "- ‘hist’ : histogram\n",
    "- ‘box’ : boxplot\n",
    "- ‘kde’ : Kernel Density Estimation plot\n",
    "- ‘density’ : same as ‘kde’\n",
    "- ‘area’ : area plot\n",
    "- ‘pie’ : pie plot\n",
    "- ‘scatter’ : scatter plot\n",
    "- ‘hexbin’ : hexbin plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "练习：根据数据绘制任意一个你想要的图表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
